{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LcAqTEOMjYMn"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install pandas_datareader\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0HH8gQW8jYMv"
   },
   "outputs": [],
   "source": [
    "# Make sure that you have all these libaries available to run the code successfully\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RCjOj0oNjYMy"
   },
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('https://raw.githubusercontent.com/minhthai1995/FIT5149/main/train_data_withlabels.csv')\n",
    "dataset_test = pd.read_csv('https://raw.githubusercontent.com/minhthai1995/FIT5149/main/test_data_nolabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DXlKjIpRjYMz",
    "outputId": "7e0bf74e-7e1e-4a56-b78f-9361b93820e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>load</th>\n",
       "      <th>ac</th>\n",
       "      <th>ev</th>\n",
       "      <th>oven</th>\n",
       "      <th>wash</th>\n",
       "      <th>dryer</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>absdif</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "      <th>entropy</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417715</th>\n",
       "      <td>523256</td>\n",
       "      <td>2.543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tue</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417716</th>\n",
       "      <td>523257</td>\n",
       "      <td>2.417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tue</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417717</th>\n",
       "      <td>523258</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tue</td>\n",
       "      <td>-1.418</td>\n",
       "      <td>1.418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417718</th>\n",
       "      <td>523259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tue</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417719</th>\n",
       "      <td>523260</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Tue</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   load  ac  ev  oven  wash  dryer  hourofday dayofweek  \\\n",
       "417715      523256  2.543   0   0     0     0      0         21       Tue   \n",
       "417716      523257  2.417   0   0     0     0      0         21       Tue   \n",
       "417717      523258  0.999   0   0     0     0      0         21       Tue   \n",
       "417718      523259  0.966   0   0     0     0      0         21       Tue   \n",
       "417719      523260  0.964   0   0     0     0      0         21       Tue   \n",
       "\n",
       "          dif  absdif  max  var  entropy  nonlinear  hurst  \n",
       "417715 -0.003   0.003  0.0  0.0      0.0        0.0    0.0  \n",
       "417716 -0.126   0.126  0.0  0.0      0.0        0.0    0.0  \n",
       "417717 -1.418   1.418  0.0  0.0      0.0        0.0    0.0  \n",
       "417718 -0.033   0.033  0.0  0.0      0.0        0.0    0.0  \n",
       "417719 -0.002   0.002  0.0  0.0      0.0        0.0    0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Vmso9W__jYNC",
    "outputId": "34cd1a83-0b7a-41bb-fb16-ae968ccd938d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>load</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>absdif</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "      <th>entropy</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.869</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.673</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.660</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.772</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.679</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   load  hourofday dayofweek    dif  absdif  max  var  entropy  \\\n",
       "0           1  1.869          0       Mon  0.000   0.000  0.0  0.0      0.0   \n",
       "1           2  1.673          0       Mon -0.196   0.196  0.0  0.0      0.0   \n",
       "2           3  1.660          0       Mon -0.013   0.013  0.0  0.0      0.0   \n",
       "3           4  1.772          0       Mon  0.112   0.112  0.0  0.0      0.0   \n",
       "4           5  1.679          0       Mon -0.093   0.093  0.0  0.0      0.0   \n",
       "\n",
       "   nonlinear  hurst  \n",
       "0        0.0    0.0  \n",
       "1        0.0    0.0  \n",
       "2        0.0    0.0  \n",
       "3        0.0    0.0  \n",
       "4        0.0    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "le_iXBFKjYNF"
   },
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIkExfOGjYNR",
    "outputId": "80599878-43de-4b93-b956-9cf39c5ee542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((417720, 16), (105540, 11), (523260, 16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape, dataset_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Qyw513xhjYNT",
    "outputId": "960fc6bb-1583-4653-eb74-b0cbc673cb68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>load</th>\n",
       "      <th>ac</th>\n",
       "      <th>ev</th>\n",
       "      <th>oven</th>\n",
       "      <th>wash</th>\n",
       "      <th>dryer</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>absdif</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "      <th>entropy</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105541</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>6.215</td>\n",
       "      <td>3.074549</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>0.052903</td>\n",
       "      <td>0.994071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105542</td>\n",
       "      <td>2.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>6.215</td>\n",
       "      <td>3.172867</td>\n",
       "      <td>0.667450</td>\n",
       "      <td>0.054829</td>\n",
       "      <td>0.994154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105543</td>\n",
       "      <td>2.269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6.215</td>\n",
       "      <td>3.270112</td>\n",
       "      <td>0.647777</td>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.994220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105544</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.215</td>\n",
       "      <td>3.303763</td>\n",
       "      <td>0.629227</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>0.994150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105545</td>\n",
       "      <td>2.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>6.215</td>\n",
       "      <td>3.302744</td>\n",
       "      <td>0.621295</td>\n",
       "      <td>0.082640</td>\n",
       "      <td>0.994041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523255</th>\n",
       "      <td>105536</td>\n",
       "      <td>1.076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.204</td>\n",
       "      <td>2.484129</td>\n",
       "      <td>0.592658</td>\n",
       "      <td>0.042413</td>\n",
       "      <td>0.990185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>105537</td>\n",
       "      <td>1.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>6.215</td>\n",
       "      <td>2.614626</td>\n",
       "      <td>0.601761</td>\n",
       "      <td>0.038118</td>\n",
       "      <td>0.990529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523257</th>\n",
       "      <td>105538</td>\n",
       "      <td>1.014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6.215</td>\n",
       "      <td>2.729923</td>\n",
       "      <td>0.629122</td>\n",
       "      <td>0.048229</td>\n",
       "      <td>0.993554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523258</th>\n",
       "      <td>105539</td>\n",
       "      <td>1.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6.215</td>\n",
       "      <td>2.868153</td>\n",
       "      <td>0.658328</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.993813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523259</th>\n",
       "      <td>105540</td>\n",
       "      <td>1.258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.247</td>\n",
       "      <td>6.215</td>\n",
       "      <td>2.972294</td>\n",
       "      <td>0.676443</td>\n",
       "      <td>0.049666</td>\n",
       "      <td>0.993965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523260 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   load   ac   ev  oven  wash  dryer  hourofday dayofweek  \\\n",
       "0           105541  2.245  0.0  0.0   0.0   0.0    0.0          0       Sun   \n",
       "1           105542  2.259  0.0  0.0   0.0   0.0    0.0          0       Sun   \n",
       "2           105543  2.269  0.0  0.0   0.0   0.0    0.0          0       Sun   \n",
       "3           105544  2.268  0.0  0.0   0.0   0.0    0.0          0       Sun   \n",
       "4           105545  2.270  0.0  0.0   0.0   0.0    0.0          0       Sun   \n",
       "...            ...    ...  ...  ...   ...   ...    ...        ...       ...   \n",
       "523255      105536  1.076  NaN  NaN   NaN   NaN    NaN         23       Sat   \n",
       "523256      105537  1.019  NaN  NaN   NaN   NaN    NaN         23       Sat   \n",
       "523257      105538  1.014  NaN  NaN   NaN   NaN    NaN         23       Sat   \n",
       "523258      105539  1.011  NaN  NaN   NaN   NaN    NaN         23       Sat   \n",
       "523259      105540  1.258  NaN  NaN   NaN   NaN    NaN         23       Sat   \n",
       "\n",
       "          dif  absdif    max       var   entropy  nonlinear     hurst  \n",
       "0       0.987   0.987  6.215  3.074549  0.678886   0.052903  0.994071  \n",
       "1       0.014   0.014  6.215  3.172867  0.667450   0.054829  0.994154  \n",
       "2       0.010   0.010  6.215  3.270112  0.647777   0.056991  0.994220  \n",
       "3      -0.001   0.001  6.215  3.303763  0.629227   0.057606  0.994150  \n",
       "4       0.002   0.002  6.215  3.302744  0.621295   0.082640  0.994041  \n",
       "...       ...     ...    ...       ...       ...        ...       ...  \n",
       "523255 -0.001   0.001  6.204  2.484129  0.592658   0.042413  0.990185  \n",
       "523256 -0.057   0.057  6.215  2.614626  0.601761   0.038118  0.990529  \n",
       "523257 -0.005   0.005  6.215  2.729923  0.629122   0.048229  0.993554  \n",
       "523258 -0.003   0.003  6.215  2.868153  0.658328   0.046729  0.993813  \n",
       "523259  0.247   0.247  6.215  2.972294  0.676443   0.049666  0.993965  \n",
       "\n",
       "[523260 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total.reset_index(inplace=True, drop=True) \n",
    "dataset_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0f7bEuspjYNV"
   },
   "outputs": [],
   "source": [
    "scale_list = ['absdif', 'dif', 'entropy', 'hurst', 'load', 'max', 'nonlinear', 'var']\n",
    "scaler = preprocessing.MinMaxScaler().fit(dataset_total[scale_list])\n",
    "dataset_total[scale_list] = scaler.transform(dataset_total[scale_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XYjX3f4ljYNa"
   },
   "outputs": [],
   "source": [
    "labelEncoderDay = preprocessing.LabelEncoder().fit(dataset_total['dayofweek'])\n",
    "labelEncoderHour = preprocessing.LabelEncoder().fit(dataset_total['hourofday'])\n",
    "dataset_total['dayofweek'] = labelEncoderDay.transform(dataset_total['dayofweek'])\n",
    "dataset_total['hourofday'] = labelEncoderHour.transform(dataset_total['hourofday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0FptlHXIxFrV"
   },
   "outputs": [],
   "source": [
    "label_list = ['ac', 'ev', 'oven', 'wash', 'dryer']\n",
    "dataset_total[label_list] = dataset_total[label_list].fillna(0.0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "1Cj3QPEbjYNd",
    "outputId": "0d3fae26-4950-4e18-d346-c81a386cd0a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>load</th>\n",
       "      <th>ac</th>\n",
       "      <th>ev</th>\n",
       "      <th>oven</th>\n",
       "      <th>wash</th>\n",
       "      <th>dryer</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>absdif</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "      <th>entropy</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523255</th>\n",
       "      <td>105536</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.509611</td>\n",
       "      <td>0.151982</td>\n",
       "      <td>0.592666</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.993362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>105537</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507602</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.159966</td>\n",
       "      <td>0.601769</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.993707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523257</th>\n",
       "      <td>105538</td>\n",
       "      <td>0.060290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.167020</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.996741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523258</th>\n",
       "      <td>105539</td>\n",
       "      <td>0.060037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511065</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.175477</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.997001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523259</th>\n",
       "      <td>105540</td>\n",
       "      <td>0.080835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527102</td>\n",
       "      <td>0.030991</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.181849</td>\n",
       "      <td>0.676451</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.997154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      load  ac  ev  oven  wash  dryer  hourofday  dayofweek  \\\n",
       "523255      105536  0.065510   0   0     0     0      0         23          2   \n",
       "523256      105537  0.060711   0   0     0     0      0         23          2   \n",
       "523257      105538  0.060290   0   0     0     0      0         23          2   \n",
       "523258      105539  0.060037   0   0     0     0      0         23          2   \n",
       "523259      105540  0.080835   0   0     0     0      0         23          2   \n",
       "\n",
       "             dif    absdif       max       var   entropy  nonlinear     hurst  \n",
       "523255  0.511194  0.000125  0.509611  0.151982  0.592666   0.000647  0.993362  \n",
       "523256  0.507602  0.007152  0.510514  0.159966  0.601769   0.000581  0.993707  \n",
       "523257  0.510937  0.000627  0.510514  0.167020  0.629130   0.000735  0.996741  \n",
       "523258  0.511065  0.000376  0.510514  0.175477  0.658337   0.000712  0.997001  \n",
       "523259  0.527102  0.030991  0.510514  0.181849  0.676451   0.000757  0.997154  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A00sup4kjYNf"
   },
   "outputs": [],
   "source": [
    "features_set = dataset_total.loc[:,dataset_total.columns.difference(['ac', 'ev', 'oven', 'wash', 'dryer' ])]\n",
    "features_set.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "# labels_set = dataset_total[['ac', 'ev', 'oven', 'wash', 'dryer']]\n",
    "labels_set = dataset_total[['ac']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "lksBdOQgjYNk",
    "outputId": "65f74508-8991-4476-921a-1be2e786ee34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absdif</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>entropy</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>hurst</th>\n",
       "      <th>load</th>\n",
       "      <th>max</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123839</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.678894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.163944</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.188105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001757</td>\n",
       "      <td>3</td>\n",
       "      <td>0.512156</td>\n",
       "      <td>0.667459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.165123</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.194120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001255</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511899</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.165965</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.200070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.629235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997339</td>\n",
       "      <td>0.165881</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.202129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511386</td>\n",
       "      <td>0.621303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997229</td>\n",
       "      <td>0.166049</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.202066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523255</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.592666</td>\n",
       "      <td>23</td>\n",
       "      <td>0.993362</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.509611</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.151982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>0.007152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507602</td>\n",
       "      <td>0.601769</td>\n",
       "      <td>23</td>\n",
       "      <td>0.993707</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.159966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523257</th>\n",
       "      <td>0.000627</td>\n",
       "      <td>2</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>23</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.060290</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.167020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523258</th>\n",
       "      <td>0.000376</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511065</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997001</td>\n",
       "      <td>0.060037</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.175477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523259</th>\n",
       "      <td>0.030991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527102</td>\n",
       "      <td>0.676451</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997154</td>\n",
       "      <td>0.080835</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.181849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          absdif  dayofweek       dif   entropy  hourofday     hurst  \\\n",
       "0       0.123839          3  0.574572  0.678894          0  0.997260   \n",
       "1       0.001757          3  0.512156  0.667459          0  0.997343   \n",
       "2       0.001255          3  0.511899  0.647785          0  0.997409   \n",
       "3       0.000125          3  0.511194  0.629235          0  0.997339   \n",
       "4       0.000251          3  0.511386  0.621303          0  0.997229   \n",
       "...          ...        ...       ...       ...        ...       ...   \n",
       "523255  0.000125          2  0.511194  0.592666         23  0.993362   \n",
       "523256  0.007152          2  0.507602  0.601769         23  0.993707   \n",
       "523257  0.000627          2  0.510937  0.629130         23  0.996741   \n",
       "523258  0.000376          2  0.511065  0.658337         23  0.997001   \n",
       "523259  0.030991          2  0.527102  0.676451         23  0.997154   \n",
       "\n",
       "            load       max  nonlinear       var  \n",
       "0       0.163944  0.510514   0.000807  0.188105  \n",
       "1       0.165123  0.510514   0.000836  0.194120  \n",
       "2       0.165965  0.510514   0.000869  0.200070  \n",
       "3       0.165881  0.510514   0.000878  0.202129  \n",
       "4       0.166049  0.510514   0.001260  0.202066  \n",
       "...          ...       ...        ...       ...  \n",
       "523255  0.065510  0.509611   0.000647  0.151982  \n",
       "523256  0.060711  0.510514   0.000581  0.159966  \n",
       "523257  0.060290  0.510514   0.000735  0.167020  \n",
       "523258  0.060037  0.510514   0.000712  0.175477  \n",
       "523259  0.080835  0.510514   0.000757  0.181849  \n",
       "\n",
       "[523260 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9M5iBLCq36ns"
   },
   "outputs": [],
   "source": [
    "#Take knowledge from the back 10 mins window, 1 mins each\n",
    "# for x in np.arange(1, 10, 1):\n",
    "#     features_set['load_before_' + str(x)] = features_set['load'].shift(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "C2_nMfYc36wU"
   },
   "outputs": [],
   "source": [
    "# features_set = features_set.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "xOwLlkvA36zO",
    "outputId": "30fb1217-9b1b-4f54-fc00-644ef469cbc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absdif</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dif</th>\n",
       "      <th>entropy</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>hurst</th>\n",
       "      <th>load</th>\n",
       "      <th>max</th>\n",
       "      <th>nonlinear</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123839</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.678894</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.163944</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.188105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001757</td>\n",
       "      <td>3</td>\n",
       "      <td>0.512156</td>\n",
       "      <td>0.667459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.165123</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.194120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001255</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511899</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.165965</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.200070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.629235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997339</td>\n",
       "      <td>0.165881</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.202129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511386</td>\n",
       "      <td>0.621303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997229</td>\n",
       "      <td>0.166049</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.202066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523255</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.592666</td>\n",
       "      <td>23</td>\n",
       "      <td>0.993362</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.509611</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.151982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>0.007152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507602</td>\n",
       "      <td>0.601769</td>\n",
       "      <td>23</td>\n",
       "      <td>0.993707</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.159966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523257</th>\n",
       "      <td>0.000627</td>\n",
       "      <td>2</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>23</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.060290</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.167020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523258</th>\n",
       "      <td>0.000376</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511065</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997001</td>\n",
       "      <td>0.060037</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.175477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523259</th>\n",
       "      <td>0.030991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527102</td>\n",
       "      <td>0.676451</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997154</td>\n",
       "      <td>0.080835</td>\n",
       "      <td>0.510514</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.181849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          absdif  dayofweek       dif   entropy  hourofday     hurst  \\\n",
       "0       0.123839          3  0.574572  0.678894          0  0.997260   \n",
       "1       0.001757          3  0.512156  0.667459          0  0.997343   \n",
       "2       0.001255          3  0.511899  0.647785          0  0.997409   \n",
       "3       0.000125          3  0.511194  0.629235          0  0.997339   \n",
       "4       0.000251          3  0.511386  0.621303          0  0.997229   \n",
       "...          ...        ...       ...       ...        ...       ...   \n",
       "523255  0.000125          2  0.511194  0.592666         23  0.993362   \n",
       "523256  0.007152          2  0.507602  0.601769         23  0.993707   \n",
       "523257  0.000627          2  0.510937  0.629130         23  0.996741   \n",
       "523258  0.000376          2  0.511065  0.658337         23  0.997001   \n",
       "523259  0.030991          2  0.527102  0.676451         23  0.997154   \n",
       "\n",
       "            load       max  nonlinear       var  \n",
       "0       0.163944  0.510514   0.000807  0.188105  \n",
       "1       0.165123  0.510514   0.000836  0.194120  \n",
       "2       0.165965  0.510514   0.000869  0.200070  \n",
       "3       0.165881  0.510514   0.000878  0.202129  \n",
       "4       0.166049  0.510514   0.001260  0.202066  \n",
       "...          ...       ...        ...       ...  \n",
       "523255  0.065510  0.509611   0.000647  0.151982  \n",
       "523256  0.060711  0.510514   0.000581  0.159966  \n",
       "523257  0.060290  0.510514   0.000735  0.167020  \n",
       "523258  0.060037  0.510514   0.000712  0.175477  \n",
       "523259  0.080835  0.510514   0.000757  0.181849  \n",
       "\n",
       "[523260 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ch_ZJlq4362o"
   },
   "outputs": [],
   "source": [
    "labels_set = labels_set.loc[9:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TJbpOzmF364p"
   },
   "outputs": [],
   "source": [
    "labels_set.reset_index(inplace=True, drop=True) \n",
    "features_set.reset_index(inplace=True, drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JQuIml035jlf"
   },
   "outputs": [],
   "source": [
    "X_train = features_set.loc[0:(dataset_train.shape[0] - 10),]\n",
    "y_train = labels_set.loc[0:(dataset_train.shape[0] - 10), ]\n",
    "\n",
    "#X_valid = labels_set \n",
    "#y_valid = \n",
    "X_test = features_set.loc[(dataset_train.shape[0] - 10):,]\n",
    "y_test = [] \n",
    "\n",
    "# I want to use a T-days window of input data for predicting target_class\n",
    "# It means I need to prepend (T-1) last train records to the 1st test window\n",
    "T = 30  # my choice of the timesteps window\n",
    "\n",
    "prepend_features = X_train.iloc[-(T-1):]\n",
    "X_test = pd.concat([prepend_features, X_test], axis=0)\n",
    "\n",
    "# Split the training into train and valid set\n",
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42, shuffle=False)\n",
    "\n",
    "prepend_features_valid = X_train_final.loc[-(T-1):]\n",
    "X_valid = pd.concat([prepend_features_valid, X_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qUGcrFS5joa",
    "outputId": "014f9a19-f319-49ab-871d-18e346c39757"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313283, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dkeKqEmLjYNp"
   },
   "outputs": [],
   "source": [
    "# X_train = features_set.iloc[0:dataset_train.shape[0],]\n",
    "# y_train = labels_set.iloc[0:dataset_train.shape[0], ]\n",
    "\n",
    "# #X_valid = labels_set \n",
    "# #y_valid = \n",
    "# X_test = features_set.iloc[dataset_train.shape[0]:,]\n",
    "# y_test = [] \n",
    "\n",
    "# # I want to use a T-days window of input data for predicting target_class\n",
    "# # It means I need to prepend (T-1) last train records to the 1st test window\n",
    "# T = 30  # my choice of the timesteps window\n",
    "\n",
    "# prepend_features = X_train.iloc[-(T-1):]\n",
    "# X_test = pd.concat([prepend_features, X_test], axis=0)\n",
    "\n",
    "# # Split the training into train and valid set\n",
    "# X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42,shuffle=False)\n",
    "\n",
    "# prepend_features_valid = X_train_final.iloc[-(T-1):]\n",
    "# X_valid = pd.concat([prepend_features_valid, X_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IZmCj0SQVLc",
    "outputId": "72783643-fbff-4e0b-e702-c36118c9f9cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313283, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIOiZ55mQVjv",
    "outputId": "0ae37bd6-0f03-4e4a-f382-87d8c184f5df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313283, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Kf7T8uX0jYOD"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "for i in range(X_train_final.shape[0] - (T-1)):\n",
    "    X_train.append(X_train_final.iloc[i:i+T].values)\n",
    "    y_train.append(y_train_final.iloc[i + (T-1)].values)\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LsrcjQ17jYOH"
   },
   "outputs": [],
   "source": [
    "X_train_LSTM, y_train_LSTM = [] , []\n",
    "X_train_LSTM = np.array(X_train)\n",
    "y_train_LSTM = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QcC_kgXjYOI",
    "outputId": "b5e3d166-7118-4d31-9760-a4854f4f3300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313254, 30, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaVg7_wEjYOh",
    "outputId": "d9c6ab62-9219-420a-ce79-f0d787973dc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313254, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fhnaCRjjjYOi"
   },
   "outputs": [],
   "source": [
    "X_valid_LSTM, y_valid_LSTM = [], []\n",
    "for i in range(y_valid.shape[0]):\n",
    "    X_valid_LSTM.append(X_valid.iloc[i:i+T].values)\n",
    "    y_valid_LSTM.append(y_valid.iloc[i])\n",
    "X_valid_LSTM, y_valid_LSTM = np.array(X_valid_LSTM), np.array(y_valid_LSTM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKO8JtX2jYOj",
    "outputId": "f147f345-fec8-4888-84a9-35c4f8c8e3e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104428, 30, 10)\n",
      "(104428, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_LSTM.shape)\n",
    "print(y_valid_LSTM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JNAonp3VjYOk"
   },
   "outputs": [],
   "source": [
    "X_test_LSTM = []\n",
    "for i in range(X_test.shape[0] - (T-1)):\n",
    "    X_test_LSTM.append(X_test.iloc[i:i+T].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fsy0H6ZUjYOl",
    "outputId": "24c3d638-1f73-4564-e07e-fa207125edec",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105550"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HPYwX-1tjYOm"
   },
   "outputs": [],
   "source": [
    "X_test_LSTM = np.array(X_test_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_x9_brsqjYOn",
    "outputId": "0ff03ea2-9ab0-4ee8-879a-4cb74946aa58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105550, 30, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_LSTM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ske0A4hijYOn"
   },
   "source": [
    "LSTM Model - Batch Training and Predictiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "JTr_fBlijYOo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wMiuKfzIjYOp"
   },
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Dropout\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp69XP3EjYOq",
    "outputId": "9400bb43-e3cc-4acd-e9a9-67862b573f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=[8, 8, 8, 1], train_examples=313254, test_examples=105550\n",
      "batch = 313254, timesteps = 30, features = 10, epochs = 200\n",
      "lr = 0.05, lambda = 0.03, dropout = 0.0, recurr_dropout = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_LSTM.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_LSTM.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_LSTM.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 200                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "V6-I8kgl8Fg0"
   },
   "outputs": [],
   "source": [
    "y_1d = y_train_LSTM.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orn9oL1C00cB",
    "outputId": "931f963c-3fe9-4c07-ff77-515860739139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4771254774366954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.73997577])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = np.sum(y_1d == 1)\n",
    "neg = np.sum(y_1d == 0)\n",
    "print(pos/neg)\n",
    "total = pos + neg\n",
    "\n",
    "\n",
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "27ExT_Se1Exd"
   },
   "outputs": [],
   "source": [
    "output_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "OxgW2-wPjYOs"
   },
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(T, N), units=LAYERS[0], return_sequences=True\n",
    "              #  activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "              #  kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              #  dropout=DP, recurrent_dropout=RDP,\n",
    "              #  return_sequences=True, return_state=False,\n",
    "              #  stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=LAYERS[1], return_sequences=True\n",
    "              #  activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "              #  kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              #  dropout=DP, recurrent_dropout=RDP,\n",
    "              #  return_sequences=True, return_state=False,\n",
    "              #  stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=LAYERS[2],\n",
    "              #  activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "              #  kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              #  dropout=DP, recurrent_dropout=RDP,\n",
    "              #  return_sequences=False, return_state=False,\n",
    "              #  stateful=False, unroll=False\n",
    "              ))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=LAYERS[3], activation='sigmoid', bias_initializer=output_bias))\n",
    "\n",
    "# model.add(Dense(units=LAYERS[3], activation='sigmoid', bias_initializer=output_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZydxoiwYEM0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkqeE7KV0gmI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEcUVjIDXl_9",
    "outputId": "bb4369ec-8f44-4681-fad0-70c4dddc64d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30, 8)             608       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 8)             544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,769\n",
      "Trainable params: 1,737\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1],\n",
    "              optimizer= 'adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "S9-pR52ly6bW"
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7Nd2VhEjYOu",
    "outputId": "a14d35f9-c56d-488a-ae48-848e7871779a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.6460 - accuracy: 0.6647 - f1: 0.0266 - val_loss: 0.4084 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.00000, saving model to model.hdf5\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6426 - accuracy: 0.6670 - f1: 0.0238 - val_loss: 0.4082 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.00000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6391 - accuracy: 0.6683 - f1: 0.0217 - val_loss: 0.4081 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.00000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6358 - accuracy: 0.6694 - f1: 0.0181 - val_loss: 0.4080 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.00000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6326 - accuracy: 0.6711 - f1: 0.0166 - val_loss: 0.4081 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.00000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.6295 - accuracy: 0.6725 - f1: 0.0145 - val_loss: 0.4082 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.00000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6269 - accuracy: 0.6733 - f1: 0.0103 - val_loss: 0.4085 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.00000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6245 - accuracy: 0.6746 - f1: 0.0080 - val_loss: 0.4089 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_f1 did not improve from 0.00000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.6223 - accuracy: 0.6753 - f1: 0.0061 - val_loss: 0.4095 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_f1 did not improve from 0.00000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6205 - accuracy: 0.6758 - f1: 0.0044 - val_loss: 0.4103 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.00000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6190 - accuracy: 0.6761 - f1: 0.0035 - val_loss: 0.4111 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.00000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.6172 - accuracy: 0.6762 - f1: 0.0027 - val_loss: 0.4122 - val_accuracy: 1.0000 - val_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.00000\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "   OOM when allocating tensor with shape[30,313254,8] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/strided_slice_2_grad/StridedSliceGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Adam/gradients/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_7342]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-43e208a57c02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# The dataset is small for NN - let's use test_data for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m classifier = model.fit(X_train_LSTM, y_train_LSTM,\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:    OOM when allocating tensor with shape[30,313254,8] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/strided_slice_2_grad/StridedSliceGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Adam/gradients/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_7342]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# # Define a learning rate decay method:\n",
    "# lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "#                              patience=1, verbose=1, \n",
    "#                              factor=0.5, min_lr=1e-8)\n",
    "# # Define Early Stopping:\n",
    "# early_stop = EarlyStopping(monitor='val_f1', min_delta=0.01, \n",
    "#                            patience=50, verbose=1, mode='auto',\n",
    "#                            baseline=0, restore_best_weights=True)\n",
    "# check_point = ModelCheckpoint('model.hdf5', monitor=\"val_f1\", mode=\"max\",\n",
    "#                               verbose=True, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor=\"val_f1\", mode=\"max\", patience=100,verbose=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "classifier = model.fit(X_train_LSTM, y_train_LSTM,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.0,\n",
    "                    validation_data=(X_valid_LSTM, y_valid_LSTM),\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a83KwP65jYOx",
    "outputId": "0e67c417-ba68-48c4-afa0-05b3bc9e9fc3"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model.evaluate(X_train_LSTM, y_train_LSTM,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "# test_loss, test_acc = model.evaluate(X_test_LSTM, y_test_LSTM,\n",
    "#                                      batch_size=M_TEST, verbose=0)\n",
    "# print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "# print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "# print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovyuRgyguzVJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TC_H8xEjYOy",
    "outputId": "20e3534f-e5ff-4c60-9af7-954541ec86b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat = model.predict_classes(X_train_LSTM, batch_size = M_TRAIN, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6yhQMJqjYO1",
    "outputId": "b6d3d236-cc73-4a8f-bd7b-35719ea30673"
   },
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTobGwtmv_oy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2ZD8hL0vKD0",
    "outputId": "01a00b75-948a-4147-d756-b5ef5df6e2c3"
   },
   "outputs": [],
   "source": [
    "type(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9A5kKe8SxM3"
   },
   "outputs": [],
   "source": [
    "y_valid_1d = y_valid_LSTM.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1d = y_train_LSTM.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjJlJJWfuFBr",
    "outputId": "37a1541a-80d2-4109-8438-ef5eb3ad9d63"
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(0, len(yhat)):\n",
    "  if yhat[i] == y_1d[i] and yhat[i] == 1:\n",
    "    sum = sum + 1\n",
    "sum\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsmohXP587uM",
    "outputId": "95140a4f-bcbd-4f80-d2d8-f6e524364696"
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in yhat:\n",
    "  if i == 1:\n",
    "    sum = sum + 1\n",
    "sum\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLLfXvPy86sd",
    "outputId": "9212c178-28e9-4caa-b6f7-e684db04b4e0"
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in y_valid_1d:\n",
    "  if i == 1:\n",
    "    sum = sum + 1\n",
    "sum\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMx-H-FOjYPG"
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_1d, yhat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pB3ve6fujYPH",
    "outputId": "d0a8f3a6-ff79-4511-eace-e7c1cbb6145f"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_1d, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94R_mkarvbPp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yve0Q-DkjYPJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD_mkdecjYPS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mQoDiXYjYPT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "XdbNEUGDjYPU",
    "outputId": "79eebc18-d855-429e-adf4-5c396d286b16"
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYjGSTg-jYPU"
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdTskVNijYPV"
   },
   "outputs": [],
   "source": [
    "y_train['transformed'] = y_train.apply(lambda x: ''.join(x.astype(str)),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDKsRCkujYPV"
   },
   "outputs": [],
   "source": [
    "le_y = preprocessing.LabelEncoder()\n",
    "y_train['encoded'] = le_y.fit_transform(y_train['transformed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sY4JsLpjYPX"
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7bpjREzjYPY"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(x_train['dayofweek'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeExXXRdjYPZ"
   },
   "outputs": [],
   "source": [
    "scale_list = ['absdif', 'dif', 'entropy', 'hurst', 'load', 'max', 'nonlinear', 'var']\n",
    "scaler = preprocessing.StandardScaler().fit(x_train[scale_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzXKfIJAjYPZ"
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul0SZtNGjYPa"
   },
   "outputs": [],
   "source": [
    "x_train['dayofweek'] = le.transform(x_train['dayofweek'])\n",
    "x_train[scale_list] = scaler.transform(x_train[scale_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muldN2kjjYPb"
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tifRenVjYPd"
   },
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfJrlyDWjYPe"
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "x_train.plot(subplots=True,\n",
    "        layout=(6, 3),\n",
    "        figsize=(22,22),\n",
    "        fontsize=10, \n",
    "        linewidth=2,\n",
    "        sharex=False,\n",
    "        title='Visualization of the original Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FamrP5vVjYPf"
   },
   "source": [
    "The raw data contain stochastic time series. Predicting/ making classification based on stochastic variable values may force the model to learn the 'persistence' mode (i.e. yhat(t+1) = y(t)), resulting in little predictive power. Defining the model to predict (make classification from) the difference in values between the time steps rather than value itself, is a stronger test of its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-KaxalPjYPg"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.copy().pct_change(1)\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZAjBpImjYPh"
   },
   "outputs": [],
   "source": [
    "x_train.fillna(method='bfill', inplace=True)\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXPw4thTjYPi"
   },
   "outputs": [],
   "source": [
    "x_train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_1mS4njYPi"
   },
   "outputs": [],
   "source": [
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(x_train, y_train, test_size = 0.4, random_state = 42,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAMhXLdUjYPj"
   },
   "outputs": [],
   "source": [
    "# I want to use a T-mins window of input data for predicting target_class\n",
    "# It means I need to prepend (T-1) last train records to the 1st test window\n",
    "T = 30  # my choice of the timesteps window\n",
    "\n",
    "prepend_features = X_train_final.iloc[-(T-1):]\n",
    "X_valid = pd.concat([prepend_features, X_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_b7aBTHjYPk"
   },
   "outputs": [],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRznP8zvjYPl"
   },
   "outputs": [],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGhSwmK0jYPm"
   },
   "outputs": [],
   "source": [
    "X_train_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8VmfvsjjYPm"
   },
   "outputs": [],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYqC1BlYjYP0"
   },
   "outputs": [],
   "source": [
    "X_train_final.shape, X_valid.shape, y_train_final.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERVMnvftjYP1"
   },
   "source": [
    "Input data for the Keras LSTM layer has 3 dimensions: (M, T, N), where\n",
    "\n",
    "- M - number of examples (2D: sequences of timesteps x features),\n",
    "- T - sequence length (timesteps) and\n",
    "- N - number of features (input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrZGvPY0jYP2"
   },
   "outputs": [],
   "source": [
    "X_train_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1TdjIp6jYP2"
   },
   "outputs": [],
   "source": [
    "# Create sequences of T timesteps\n",
    "X_train_LSTM, y_train_LSTM = [], []\n",
    "for i in range(y_train_final.shape[0] - (T-1)):\n",
    "    X_train_LSTM.append(X_train_final.iloc[i:i+T].values)\n",
    "    y_train_LSTM.append(y_train_final.iloc[i + (T-1)])\n",
    "# X_train_LSTM, y_train_LSTM = np.array(X_train_LSTM), np.array(y_train_LSTM).reshape(-1,1)\n",
    "# print(f'Train data dimensions: {X_train_LSTM.shape}, {y_train_LSTM.shape}')\n",
    "\n",
    "# X_valid, y_test = [], []\n",
    "# for i in range(test_labels.shape[0]):\n",
    "#     X_test.append(scaled_test_features.iloc[i:i+T].values)\n",
    "#     y_test.append(test_labels.iloc[i])\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test).reshape(-1,1)  \n",
    "\n",
    "# print(f'Test data dimensions: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Csrbo2CjYP3"
   },
   "outputs": [],
   "source": [
    "X_train_LSTM\n",
    "X_train_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeInIx2BjYP4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wmFsha9jYP4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sniJu7zfjYP5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xKMWTn2jYP5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split train and validation data\n",
    "train_features = x_train.loc['2012-01-02':'2016-12-31']\n",
    "train_labels = df.loc['2012-01-02':'2016-12-31', 'target_class']\n",
    "\n",
    "test_features = df_transform.loc['2017-01-02':'2018-06-19']\n",
    "test_labels = df.loc['2017-01-02':'2018-06-19', 'target_class']\n",
    "\n",
    "# I want to use a T-days window of input data for predicting target_class\n",
    "# It means I need to prepend (T-1) last train records to the 1st test window\n",
    "T = 45  # my choice of the timesteps window\n",
    "\n",
    "prepend_features = train_features.iloc[-(T-1):]\n",
    "test_features = pd.concat([prepend_features, test_features], axis=0)\n",
    "\n",
    "train_features.shape, train_labels.shape, test_features.shape, test_labels.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bản sao của Bản sao của Thai Nguyen LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
